{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [IAPR 2019:][iapr2019] Lab 1 ‒  Image segmentation\n",
    "\n",
    "**Author:** Adrien Lüthi and Elias Gajo  \n",
    "**Due date:** 04.04.2019\n",
    "\n",
    "[iapr2019]: https://github.com/LTS5/iapr-2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract relevant data\n",
    "We first need to extract the `lab-01-data.tar.gz` archive.\n",
    "To this end, we use the [tarfile] module from the Python standard library.\n",
    "\n",
    "[tarfile]: https://docs.python.org/3.6/library/tarfile.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '..\\\\data\\\\lab-01-data.tar.gz'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-685121e658c3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdata_folder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'lab-01-data'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mtar_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_base_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_folder\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'.tar.gz'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mtarfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtar_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'r:gz'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtar\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mtar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata_base_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\tarfile.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(cls, name, mode, fileobj, bufsize, **kwargs)\u001b[0m\n\u001b[0;32m   1589\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1590\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mCompressionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"unknown compression type %r\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mcomptype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1591\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilemode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfileobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1592\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1593\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[1;34m\"|\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\tarfile.py\u001b[0m in \u001b[0;36mgzopen\u001b[1;34m(cls, name, mode, fileobj, compresslevel, **kwargs)\u001b[0m\n\u001b[0;32m   1636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1637\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1638\u001b[1;33m             \u001b[0mfileobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgzip\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGzipFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"b\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompresslevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfileobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1639\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1640\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mfileobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\gzip.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, filename, mode, compresslevel, fileobj, mtime)\u001b[0m\n\u001b[0;32m    161\u001b[0m             \u001b[0mmode\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;34m'b'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfileobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 163\u001b[1;33m             \u001b[0mfileobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmyfileobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    164\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfilename\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m             \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'name'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '..\\\\data\\\\lab-01-data.tar.gz'"
     ]
    }
   ],
   "source": [
    "import tarfile\n",
    "import os\n",
    "\n",
    "data_base_path = os.path.join(os.pardir, 'data')\n",
    "data_folder = 'lab-01-data'\n",
    "tar_path = os.path.join(data_base_path, data_folder + '.tar.gz')\n",
    "with tarfile.open(tar_path, mode='r:gz') as tar:\n",
    "    tar.extractall(path=data_base_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Brain segmentation\n",
    "\n",
    "Your goal: compute the size of the brain (in pixels) in a 2D image of a human head taken by Magnetic Resonance Imaging (MRI).\n",
    "* Try as many methods as you can, the more the better.\n",
    "* At least region growing and contour detection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Brain image visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage.io\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "%matplotlib inline\n",
    "\n",
    "# Load image\n",
    "data_path = os.path.join(data_base_path, data_folder)\n",
    "brain_im = skimage.io.imread(os.path.join(data_path, 'brain-slice40.tiff'))\n",
    "im_h, im_w = brain_im.shape\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
    "ax.imshow(brain_im, cmap='gray')\n",
    "ax.set_title('MRI brain image ({} px, {} px)'.format(im_h, im_w))\n",
    "ax.axis('on')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Region growing\n",
    "Nous pouvons chercher la taille du cerveau par la technique du region growing. L'idée sera donc de faire grossir notre région (correspondant au cerveau) jusqu'à ce que le crâne soit détecté. Il faudra donc choisir un critère d'homogénéité permettant de détecter un pixel du crâne. Nous voyons que les pixels du crâne sont facilement reconnaissables puisqu'ils sont bien blancs. Pour trouver le threshold adéquat (la valeur minimale d'un pixel du crâne), nous pouvons dans un premier temps recourir à l'histogramme.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nb_bins = 256\n",
    "\n",
    "# Display histogram\n",
    "plt.figure(figsize=(12, 7))\n",
    "plt.hist(brain_im.ravel(), bins=nb_bins)\n",
    "plt.xlabel('Pixel intensity')\n",
    "plt.ylabel('Number of pixels')\n",
    "plt.title('256 bins histogram')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous n'arrivons pas à lire clairement un pic pour les intensités correspondant au crâne. Nous allons donc estimer la valeur moyenne d'un pixel du cerveau, et définir un écart maximum (comme critère d'homogénéité). Pour estimer la valeur moyenne d'un pixel du cerveau, visualisons les valeurs des pixels dans une région de l'image correspondant clairement au cerveau. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'brain_im' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-3d875db15913>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mvaleur_cerveau\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbrain_im\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m140\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m160\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m60\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m80\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvaleur_cerveau\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'brain_im' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "valeur_cerveau = brain_im[140:160,60:80]\n",
    "print(valeur_cerveau)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En analysant cette région de l'image et l'histogramme, nous pouvons estimer que la valeur moyenne des pixels du cerveau est de 80. Nous appliquons la même méthode pour trouver la valeur typique d'un pixel du crâne et d'un pixel du background. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valeur_crane = brain_im[65:75,95:105]\n",
    "print(valeur_crane)\n",
    "valeur_background = brain_im[60:70,115:125]\n",
    "print(valeur_background)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "J'ai choisis les valeurs initiales en m'inspirant de ces valeurs. J'ai commencé avec une valeur de 110 pour définir le threshold du crâne, et de 40 pour définir celui du background. Après avoir programmé l'algorithme, nous avons modifié un peu les valeurs de threshold initiales pour avoir un bon résultat. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regionGrowing(img_in, thresh_l, thresh_h, initial_point):\n",
    "    import numpy as np\n",
    "    im_h, im_w = img_in.shape\n",
    "    img_out = np.zeros((im_h,im_w))\n",
    "    img_out[initial_point[0], initial_point[1]] = 1\n",
    "    point = initial_point\n",
    "\n",
    "    while(len(point) > 1):\n",
    "        #chercher les voisins du premier point de la liste\n",
    "        if (point[0] > 0):\n",
    "            next_point = [point[0] - 1, point[1]]\n",
    "            val_pix = img_in[next_point[0], next_point[1]]\n",
    "            if (val_pix > thresh_l and val_pix < thresh_h and img_out[next_point[0], next_point[1]] < 1):\n",
    "                point = point + next_point\n",
    "                img_out[next_point[0], next_point[1]] = 1\n",
    "\n",
    "        if (point[1] > 0):\n",
    "            next_point = [point[0], point[1] - 1]\n",
    "            val_pix = img_in[next_point[0], next_point[1]]\n",
    "            if (val_pix > thresh_l and val_pix < thresh_h and img_out[next_point[0], next_point[1]] < 1):\n",
    "                point = point + next_point\n",
    "                img_out[next_point[0], next_point[1]] = 1\n",
    "\n",
    "        if (point[0] < 255):\n",
    "            next_point = [point[0] + 1, point[1]]\n",
    "            val_pix = img_in[next_point[0], next_point[1]]\n",
    "            if (val_pix > thresh_l and val_pix < thresh_h and img_out[next_point[0], next_point[1]] < 1):\n",
    "                point = point + next_point\n",
    "                img_out[next_point[0], next_point[1]] = 1\n",
    "\n",
    "        if (point[1] < 255):\n",
    "            next_point = [point[0], point[1] + 1]\n",
    "            val_pix = img_in[next_point[0], next_point[1]]\n",
    "            if (val_pix > thresh_l and val_pix < thresh_h and img_out[next_point[0], next_point[1]] < 1):\n",
    "                point = point + next_point\n",
    "                img_out[next_point[0], next_point[1]] = 1\n",
    "\n",
    "        del(point[0])\n",
    "        del(point[0])\n",
    "    return img_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculSize (cerveau):\n",
    "    column = 0\n",
    "    aire = 0;\n",
    "    while (column < 255):\n",
    "\n",
    "        pixel_of_column = 0;\n",
    "        #search the first and last white pixels\n",
    "        first = 0;\n",
    "        while(first < 255):\n",
    "            if(cerveau[first, column] > 0):\n",
    "                break\n",
    "            first = first + 1\n",
    "\n",
    "        last = 255;\n",
    "        while(last > 0):\n",
    "            if(cerveau[last, column] > 0):\n",
    "                break\n",
    "            last = last - 1\n",
    "\n",
    "        if((first ==255) or (last == 0)):\n",
    "            pixel_of_column = 0\n",
    "        else:\n",
    "            pixel_of_column = last - first + 1\n",
    "\n",
    "        aire = aire + pixel_of_column\n",
    "        column = column + 1\n",
    "\n",
    "    rayon = np.sqrt(aire/np.pi)\n",
    "    taille = 2 * rayon #diamètre\n",
    "    print(\"On trouve une taille de\",taille, \"ce qui parait cohérent en regardant l'image. \")\n",
    "    return;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage.filters\n",
    "import numpy as np\n",
    "import skimage.io\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "%matplotlib inline\n",
    "\n",
    "# Load image\n",
    "data_path = os.path.join(data_base_path, data_folder)\n",
    "brain_im = skimage.io.imread(os.path.join(data_path, 'brain-slice40.tiff'))\n",
    "\n",
    "#threshold pour isoler le cerveau\n",
    "thresh_h = 90\n",
    "thresh_l = 50\n",
    "\n",
    "initial_point = [150,70]\n",
    "cerveau = regionGrowing(brain_im, thresh_l, thresh_h, initial_point)\n",
    "plt.figure(figsize=(12, 7))\n",
    "plt.imshow(cerveau, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant que le cerveau est bien isolé du reste, nous pouvons essayer d'estimer sa taille. Nous remarquons que la forme du cerveau est presque ronde. Nous pouvons donc facilement estimer son rayon par la formule A = pi r^2.\n",
    "Le calcul va donc se faire en 2 temps. D'abord l'aire du cerveau va être estimée en comptant le nombre de pixel délimités par le contour du cerveau. Et ensuite, la taille (le diamètre) va être calculée par rapport à cette aire estimée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculSize(cerveau)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Contour detection\n",
    "Add your implementation and discussion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import skimage.filters\n",
    "import numpy as np\n",
    "from scipy import ndimage as ndi\n",
    "from skimage import measure\n",
    "from skimage import feature\n",
    "from skimage import filters\n",
    "from skimage.morphology import reconstruction\n",
    "from skimage.morphology import binary_closing\n",
    "from skimage import feature\n",
    "\n",
    "from skimage.filters import roberts, sobel, scharr, prewitt\n",
    "\n",
    "\n",
    "markers = np.zeros_like(brain_im)\n",
    "c = np.ones_like(brain_im)\n",
    "\n",
    "markers[brain_im <= 60] = 255\n",
    "markers[brain_im > 55] = 0\n",
    "markers[brain_im > 78] = 255\n",
    "\n",
    "\n",
    "cerveau = skimage.morphology.closing(markers, selem=skimage.morphology.selem.disk(1), out=None)\n",
    "cerveau_cut = np.copy(cerveau)\n",
    "\n",
    "limit_left = np.arange(49)\n",
    "for i in limit_left: \n",
    "    cerveau_cut[:,i] = 255\n",
    "    \n",
    "limit_right = np.arange(203, 256)\n",
    "for i in limit_right: \n",
    "    cerveau_cut[:,i] = 255\n",
    "    \n",
    "limit_top = np.arange(0, 75)\n",
    "for i in limit_top: \n",
    "    cerveau_cut[i,:] = 255\n",
    "    \n",
    "limit_diag_right_x = np.arange(40, 100)\n",
    "limit_diag_right_y = np.arange(0, 170)\n",
    "for j in limit_diag_right_y:\n",
    "    for i in limit_diag_right_x:\n",
    "        th_y = np.int(np.ceil((-126/62)*i + 223))\n",
    "        if j < th_y:\n",
    "            cerveau_cut[j, i] = 255\n",
    "            \n",
    "limit_diag_left_x = np.arange(150, 250)\n",
    "limit_diag_left_y = np.arange(0, 130)\n",
    "for j in limit_diag_left_y:\n",
    "    for i in limit_diag_left_x:\n",
    "        th_y = np.int(np.ceil((1.6)*i - 200))\n",
    "        if j < th_y:\n",
    "            cerveau_cut[j, i] = 255\n",
    "            \n",
    "\n",
    "cerveau_open = skimage.morphology.opening(cerveau_cut, selem=skimage.morphology.selem.disk(5), out=None)\n",
    "cerveau_open = np.invert(cerveau_open)\n",
    "\n",
    "seed = np.copy(cerveau_open)\n",
    "seed[1:-1, 1:-1] = cerveau_open.max()\n",
    "mask = cerveau_open\n",
    "\n",
    "cerveau_filled = reconstruction(seed, mask, method='erosion')\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(ncols=3, sharex=True, sharey=True,\n",
    "                       figsize=(8, 4))\n",
    "\n",
    "ax1.imshow(cerveau_cut, cmap=plt.cm.gray)\n",
    "ax1.set_title('Cut')\n",
    "\n",
    "ax2.imshow(cerveau_open, cmap=plt.cm.gray)\n",
    "ax2.set_title('Opening')\n",
    "\n",
    "ax3.imshow(cerveau_filled, cmap=plt.cm.gray)\n",
    "ax3.set_title('Black Hols Filled')\n",
    "\n",
    "calculSize(cerveau_filled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Additional method(s)\n",
    "Add your implementation and discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici, nous appliquons une méthode simple qui consite à estimer la largeur du cerveau suivant une ligne de coordonnée y = 150. L'algorithme va donc chercher, par le biais de thresholds, le premier et le dernier pixel appartenant au cerveau. La condition se base sur un booléen qui s'active lorsqu'on franchit le crâne, et sur des thresholds reconnaissant un pixel du cerveau. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#threshold pour isoler le cerveau\n",
    "import numpy as np\n",
    "img = brain_im\n",
    "cerveau = np.copy(img)\n",
    "threshCrane = 100\n",
    "threshBlack = 70\n",
    "y = 150\n",
    "#detect first brain pixel\n",
    "xmin = 0\n",
    "skullReached = False\n",
    "while(xmin < 255):\n",
    "    if(cerveau[y,xmin] > threshCrane):\n",
    "        skullReached = True\n",
    "    if(cerveau[y,xmin] > threshBlack) and (cerveau[y,xmin] < threshCrane) and skullReached:\n",
    "        break\n",
    "    xmin = xmin + 1\n",
    "skullReached = False\n",
    "xmax = 255\n",
    "while(xmin > 0):\n",
    "    if(cerveau[y,xmax] > threshCrane):\n",
    "        skullReached = True\n",
    "    if(cerveau[y,xmax] > threshBlack) and (cerveau[y,xmax] < threshCrane) and skullReached:\n",
    "        break\n",
    "    xmax = xmax - 1\n",
    "size = xmax - xmin\n",
    "print(size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ceci nous donne une taille de 161 pixels. Le résultat ressemble aux précédents, même si la technique utilisée est moins formelle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Save the bees !\n",
    "\n",
    "Varroa mites are recognized as the biggest pest to honey bees worldwide, and are believed to be the single largest contributing factor in the modern-day decline of honey bees due to their ability to transmit diseases, resulting in death or severe deformity of the pupae. \n",
    "\n",
    "Detecting and quantifying the presence of Verroa in a beehive is therefore crucial to treat the infection appropriately and as early as possible, and image analysis appears very useful in this problem.\n",
    "\n",
    "![Varroa Mite](https://lts5www.epfl.ch/wp-content/uploads/2018/07/varroa-2.jpg)\n",
    "\n",
    "\n",
    "\n",
    "### 2.1 Introduction to Project\n",
    "\n",
    "You will find hereafter a set of 4 images taken under real conditions. In this task you will be ask to:\n",
    "1. Count the number of Varroa on each picture\n",
    "2. Determine the Intersection over Union of the detected patterns w.r.t. the ground truth\n",
    "3. Estimate the Precision, Recall and F1-score at two different IoU thresholds $T = {0.5 \\text{, and } 0.9}$\n",
    "\n",
    "\n",
    "**Note** \n",
    "\n",
    "Try to have the same routine(s) running on the four images, and giving (approximatively) the same results. The routine(s) that you will write for this part will be useful for the final project as well, so pay special attention to it.\n",
    "\n",
    "#### Vocabulary\n",
    "\n",
    "\n",
    "* **IoU**: Let $A$ be the ground truth area and $B$ the predicted one. the intersection over union (IoU) is given as:\n",
    "$$IoU(A,B) = \\frac{A \\cap B}{A \\cup B} = \\frac{\\text{Area of Overlap}}{\\text{Area of Union}}$$\n",
    "Let $T$ be a scalar in the interval $[0, 1]$, then $B$ will be considered as a true positive (TP) if and only if $IoU(A,B) \\ge T$. As a results, we can evaluate the performance of our detection with different values of $T$. The larger $T$ is, the more constraining is our condition.\n",
    "\n",
    "\n",
    "* **Precision**: The precision is given as:\n",
    "$$precision = \\frac{tp}{tp + fp}$$\n",
    "where $tp$ is the number of true positives and $fp$ the number of false positives. The precision is intuitively the ability of the classifier not to label as positive a sample that is negative.\n",
    "\n",
    "\n",
    "* **Recall**: The recall is given as:\n",
    "$$precision = \\frac{tp}{tp + fn}$$\n",
    "where $tp$ is the number of true positives and $fn$ the number of false negatives. The recall is intuitively the ability of the classifier to find all the positive samples.\n",
    "\n",
    "\n",
    "* **F1-score**: The F1 score can be interpreted as a weighted average of the precision and recall, where an F1 score reaches its best value at 1 and worst score at 0. The relative contribution of precision and recall to the F1 score are equal. The formula for the F1 score is:\n",
    "$$F1 = \\frac{2 \\cdot precision \\cdot recall}{precision + recall}$$\n",
    "\n",
    "\n",
    "**FAQ**\n",
    "\n",
    "Q: What to do if I have multiple ground truth $A_i$ and candidates $B_j$ and want to find the best set $(i,j)$ such that $(i, j) = \\arg\\max_{i,j} IoU(A_i, B_j)$ ? \n",
    "\n",
    "A: Here, we recommend to use a brute force approach. It corresponds to compute $IoU(A, B)$ for every possible pairs (i,j) and keep the pair with the highest $IoU$. Note that a candidate $B_j$ can **only** be matched to **one** ground truth area $A_i$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we visualize the 4 images for our patern detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images\n",
    "im_names = ['varroa-01', 'varroa-02', 'varroa-03', 'varroa-04']\n",
    "filenames = [os.path.join(data_path, name) + '.jpg' for name in im_names]\n",
    "ic = skimage.io.imread_collection(filenames)\n",
    "print('Number of images: ', len(ic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot images\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 12))\n",
    "for ax, im, nm in zip(axes.ravel(), ic, im_names):\n",
    "    ax.imshow(im)\n",
    "    ax.axis('off')\n",
    "    ax.set_title(nm)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can as well add the groud truth label that are stored in the corresponding XML files. Each xml file stores the position of the varroa on the image as :\n",
    "\n",
    "```xml\n",
    "<annotation>\n",
    "\t<object>\n",
    "\t\t<name>Varroa</name>\n",
    "\t\t<difficult>0</difficult>\n",
    "\t\t<bndbox>\n",
    "\t\t\t<xmin>14</xmin>\n",
    "\t\t\t<ymin>117</ymin>\n",
    "\t\t\t<xmax>33</xmax>\n",
    "\t\t\t<ymax>137</ymax>\n",
    "\t\t</bndbox>\n",
    "\t</object>\n",
    "\t<object>\n",
    "\t\t...\n",
    "\t</object>\n",
    "\t...\n",
    "</annotation>\n",
    "```\n",
    "The block `object` defines the attributes of the varroa. `name` is the definition of the object class (always varroa). `bndbox` is the definition of the bounding box. To simplify your task, we implemented a function named `parse_file` that returns an array with the bounding box of the varroa expressed as `(x, y, width, heigth)` which corresponds to `(xmin, ymin, xmax-xmin, ymax-ymin)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "def parse_file(filename):\n",
    "    \"\"\" Parse a PASCAL VOC xml file \"\"\"\n",
    "    tree = ET.parse(filename)\n",
    "    objects = []\n",
    "    for obj in tree.findall('object'):\n",
    "        obj_struct = {}\n",
    "        obj_struct['name'] = obj.find('name').text\n",
    "        bbox = obj.find('bndbox')\n",
    "        obj_struct['bbox'] = [int(float(bbox.find('xmin').text)),\n",
    "                              int(float(bbox.find('ymin').text)),\n",
    "                              int(float(bbox.find('xmax').text))-int(float(bbox.find('xmin').text)),\n",
    "                              int(float(bbox.find('ymax').text))-int(float(bbox.find('ymin').text))]\n",
    "        objects.append(obj_struct)\n",
    "\n",
    "    return objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_xmls = [parse_file(os.path.join(data_path, name) + '.xml') for name in im_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot images\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 12))\n",
    "for ax, im, nm, annotations in zip(axes.ravel(), ic, im_names, annotations_xmls):\n",
    "    # Iterate over annotations\n",
    "    for anno in annotations:\n",
    "        rect = patches.Rectangle((anno['bbox'][0], anno['bbox'][1]), anno['bbox'][2], anno['bbox'][3],\n",
    "                linewidth=1,edgecolor='r',facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "    \n",
    "    ax.imshow(im)\n",
    "    ax.axis('off')\n",
    "    ax.set_title(nm)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Count the number of Varroa on each picture\n",
    "\n",
    "Add your implementation and discussion\n",
    "\n",
    "Hint: `skimage.measure.label` might be useful to label the thresholded image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tout d'abord, regardons quelle plage de couleur nous donne le plus de contraste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage.io\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import skimage.filters\n",
    "import skimage.color\n",
    "import numpy as np\n",
    "from skimage import exposure\n",
    "import os\n",
    "data_base_path = os.path.join(os.pardir, 'data')\n",
    "data_folder = 'lab-01-data'\n",
    "data_path = os.path.join(data_base_path, data_folder)\n",
    "img= skimage.io.imread(os.path.join(data_path, 'varroa-02.jpg'))\n",
    "im_h, im_w, nb_color = img.shape\n",
    "plt.imshow(img)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3)\n",
    "fig.set_size_inches(18.5, 10.5)\n",
    "axes[0].imshow(img[:,:,0])\n",
    "axes[0].set_title(\"Red channel\")\n",
    "axes[1].imshow(img[:,:,1])\n",
    "axes[1].set_title(\"Green channel\")\n",
    "axes[2].imshow(img[:,:,2])\n",
    "axes[2].set_title(\"Blue channel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous voyons ici que la plage rouge se prête bien pour isoler les mites du background. Nous nous somme donc basé uniquement sur le rouge pour la suite. Nous aurions pu être plus rigoureux, et chercher numériquement pour chaque image, quelle couleur donne le plus de contraste.\n",
    "Pour la suite, nous commençons par appliquer la technique du region growing avec un threshold permettant de maximiser nos chances de développer les formes des mites sans développer celles du background. Nous avons donc modifier le threshold pour chaque image, afin d'optimiser les résultats obtenus. \n",
    "Comme pour la plupart des images, l'algorithme développait aussi la forme de petits éléments du background, nous avons choisi de remédier à ça en appliquant l'algorithme opening avec un masque adéquat. Le masque qui nous donnait les meilleurs résultats était sans surprise le masque circulaire (puisque les mites sont de forme presque ronde). Nous avons également adapté le rayon de ce masque pour chaque image afin d'optimiser les résultats.\n",
    "Enfin, comme sur certaines images, il y avait des gros objets appartenant au background, nous avons appliqué un autre algorithme (nommé removeNoise), qui se charge de supprimer toutes les formes trop grandes ou trop petites. La raison était que la taille des mites semblait plutôt constante, contrairement à celle des éléments du background. Cette algorithme calcul la taille moyenne des formes (élaborées par region growing), et l'écart type. Ensuite, il supprime les formes dont la taille s'écarte trop de la moyenne (toutes les formes plus grandes ou plus petites que mean +- facteur * std). Le \"facteur\" est également un paramètre que nous pouvons modifier pour chaque image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def completeRegionGrowing(img, thresh_black, tolerance):\n",
    "    import numpy as np\n",
    "    x = 0\n",
    "    im_h, im_w = img.shape\n",
    "    img_out = np.zeros((im_h, im_w))\n",
    "    label = 0\n",
    "    while(x < im_w):\n",
    "        y = 0\n",
    "        while(y < im_h):\n",
    "            if(img[y,x]> thresh_black):\n",
    "                y = y + 1\n",
    "                continue\n",
    "            if(img_out[y,x] > 0): # déja labellé\n",
    "                y = y + 1\n",
    "                continue\n",
    "            # region growing\n",
    "            initial_point = [y,x]\n",
    "            val_pix = img[y,x]\n",
    "            if((val_pix + tolerance) > 255):\n",
    "                thresh_h = 255\n",
    "            else:\n",
    "                thresh_h = val_pix + tolerance\n",
    "            if((val_pix - tolerance) < 0):\n",
    "                thresh_l = 0\n",
    "            else:\n",
    "                thresh_l = val_pix - tolerance\n",
    "            point = initial_point\n",
    "            label = label + 1\n",
    "            img_out[initial_point[0], initial_point[1]] = label\n",
    "            while(len(point) > 1):\n",
    "                #chercher les voisins du premier point de la liste\n",
    "                if (point[0] > 0):\n",
    "                    next_point = [point[0] - 1, point[1]]\n",
    "                    val_pix = img[next_point[0], next_point[1]]\n",
    "                    if (val_pix >= thresh_l and val_pix <= thresh_h and img_out[next_point[0], next_point[1]] < label):\n",
    "                        point = point + next_point\n",
    "                        img_out[next_point[0], next_point[1]] = label\n",
    "\n",
    "                if (point[1] > 0):\n",
    "                    next_point = [point[0], point[1] - 1]\n",
    "                    val_pix = img[next_point[0], next_point[1]]\n",
    "                    if (val_pix >= thresh_l and val_pix <= thresh_h and img_out[next_point[0], next_point[1]] < label):\n",
    "                        point = point + next_point\n",
    "                        img_out[next_point[0], next_point[1]] = label\n",
    "\n",
    "                if (point[0] < (im_h - 1)):\n",
    "                    next_point = [point[0] + 1, point[1]]\n",
    "                    val_pix = img[next_point[0], next_point[1]]\n",
    "                    if (val_pix >= thresh_l and val_pix <= thresh_h and img_out[next_point[0], next_point[1]] < label):\n",
    "                        point = point + next_point\n",
    "                        img_out[next_point[0], next_point[1]] = label\n",
    "\n",
    "                if (point[1] < (im_w - 1)):\n",
    "                    next_point = [point[0], point[1] + 1]\n",
    "                    val_pix = img[next_point[0], next_point[1]]\n",
    "                    if (val_pix >= thresh_l and val_pix <= thresh_h and img_out[next_point[0], next_point[1]] < label):\n",
    "                        point = point + next_point\n",
    "                        img_out[next_point[0], next_point[1]] = label\n",
    "\n",
    "                del(point[0])\n",
    "                del(point[0])\n",
    "            y = y + 1\n",
    "        x = x + 1\n",
    "    print(label)\n",
    "    return img_out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maskCircle(rayon):\n",
    "    import numpy as np\n",
    "    mask = np.zeros((rayon*2 + 1,rayon*2 + 1))\n",
    "    x = 0\n",
    "    while(x < rayon*rayon + 1):\n",
    "        y = 0\n",
    "        while(y < rayon*rayon + 1):\n",
    "            if(((x - rayon)*(x - rayon) + (y - rayon)*(y - rayon))<= rayon*rayon):\n",
    "                mask[x,y] = 1\n",
    "            y = y + 1\n",
    "        x = x + 1\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_noise(img_test,nb_of_sigma): #sigma is the standard deviation\n",
    "    import numpy as np\n",
    "    cleaned_img = np.uint64(np.copy(img_test))\n",
    "    num_comp = np.amax(cleaned_img)\n",
    "    sizeOfRegion = np.zeros(num_comp)\n",
    "    \n",
    "    for i in range(num_comp):\n",
    "        total = sum(sum(cleaned_img==(i+1)))\n",
    "        sizeOfRegion[i] = total\n",
    "        \n",
    "    mean = np.mean(sizeOfRegion)\n",
    "    sigma = np.std(sizeOfRegion)\n",
    "    \n",
    "    for i in range(num_comp):\n",
    "        num_pixels = sizeOfRegion[i]\n",
    "        if (num_pixels < (mean - nb_of_sigma*sigma)) or (num_pixels > (mean + nb_of_sigma*sigma)):\n",
    "            cleaned_img[cleaned_img==(i+1)] = 0\n",
    "    \n",
    "    return cleaned_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeCenterPoints(labelled_img):\n",
    "    import numpy as np\n",
    "    num_comp = np.max(labelled_img)\n",
    "    center = np.zeros((num_comp,2))\n",
    "    for i in range(num_comp):\n",
    "        coord = labelled_img==(i+1)\n",
    "        im_h, im_w = coord.shape\n",
    "        listx = []\n",
    "        listy = []\n",
    "        for y in range(im_h):\n",
    "            for x in range(im_w):\n",
    "                if(coord[y,x]):\n",
    "                    listx.append(x)\n",
    "                    listy.append(y)\n",
    "        \n",
    "        x_center = np.mean(listx)\n",
    "        y_center = np.mean(listy)\n",
    "        center[i,0] = y_center\n",
    "        center[i,1] = x_center\n",
    "    return center"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans le programme ci-dessous, une seule image est considérée. Pour modifier l'image, voici la procédure : \n",
    "1) modifier le nom de l'image dans cette ligne --> img= skimage.io.imread(os.path.join(data_path, 'varroa-01.jpg'))\n",
    "2) Repérer les paramètre associés à l'image voulu, exemple --> #completeRegionGrowing parameters - varroa-02 \n",
    "3) décommenter les paramètres sous cette ligne, et commenter les paramètres de l'image précédente.\n",
    "4) enjoy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "import skimage.io\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import skimage.filters\n",
    "import skimage.color\n",
    "import skimage.measure\n",
    "import numpy as np\n",
    "from skimage import exposure\n",
    "%matplotlib inline\n",
    "data_base_path = os.path.join(os.pardir, 'data')\n",
    "data_folder = 'lab-01-data'\n",
    "data_path = os.path.join(data_base_path, data_folder)\n",
    "img= skimage.io.imread(os.path.join(data_path, 'varroa-02.jpg'))\n",
    "im_h, im_w, nb_color = img.shape\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
    "ax.imshow(img, cmap='gray')\n",
    "ax.set_title('image ({} px, {} px)'.format(im_h, im_w))\n",
    "ax.axis('on')\n",
    "plt.show()\n",
    "\n",
    "#img = img < 0.2\n",
    "\n",
    "#plt.figure(figsize=(12, 7))\n",
    "#plt.imshow(img, cmap='gray')\n",
    "#plt.show()\n",
    "\n",
    "r = img[:,:,0]\n",
    "g = img[:,:,1]\n",
    "b = img[:,:,2]\n",
    "\n",
    "#img = skimage.color.rgb2gray(img)\n",
    "img_hist, bins = exposure.histogram(img)\n",
    "#plt.plot(bins, img_hist)\n",
    "\n",
    "#completeRegionGrowing parameters - varroa-01\n",
    "#thresh_black = 40\n",
    "#tolerance = 60\n",
    "#rayon = 4\n",
    "#nb_of_sigma = 2\n",
    "\n",
    "#completeRegionGrowing parameters - varroa-02\n",
    "thresh_black = 125\n",
    "tolerance = 60\n",
    "rayon = 5\n",
    "nb_of_sigma = 2\n",
    "\n",
    "#completeRegionGrowing parameters - varroa-03\n",
    "#thresh_black = 40\n",
    "#tolerance = 60\n",
    "#rayon = 4\n",
    "#nb_of_sigma = 2\n",
    "\n",
    "#completeRegionGrowing parameters - varroa-04\n",
    "#thresh_black = 100\n",
    "#tolerance = 100\n",
    "#rayon = 4\n",
    "#nb_of_sigma = 2\n",
    "\n",
    "#masks for opening\n",
    "mask1 = np.ones((2*rayon,2*rayon))\n",
    "mask2 = maskCircle(rayon)\n",
    "\n",
    "#tolerance = 0.2\n",
    "#img_hist, bins = exposure.histogram(r)\n",
    "#plt.plot(bins, img_hist)\n",
    "img_out = completeRegionGrowing(r, thresh_black, tolerance)\n",
    "\n",
    "#print(np.max(img_out)) \n",
    "#plt.figure(figsize=(12, 7))\n",
    "#plt.imshow(img_out, cmap='gray')\n",
    "#plt.show()\n",
    "\n",
    "img_out = remove_noise(img_out,nb_of_sigma)\n",
    "skimage.morphology.binary_opening(img_out, mask2, out = img_out)\n",
    "\n",
    "varroa = skimage.measure.label(img_out)\n",
    "#plt.figure(figsize=(12, 7))\n",
    "#plt.imshow(img_out, cmap='gray')\n",
    "#plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si l'image a été changée au dessus, il faut également changer le nom de l'image dans la première ligne du code qui suit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_xmls = [parse_file(os.path.join(data_path, 'varroa-02') + '.xml')]\n",
    "%matplotlib inline\n",
    "# Plot images\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 12))\n",
    "for ax, im, nm, annotations in zip(axes.ravel(), ic, im_names, annotations_xmls):\n",
    "    # Iterate over annotations\n",
    "    for anno in annotations:\n",
    "        rect = patches.Rectangle((anno['bbox'][0], anno['bbox'][1]), anno['bbox'][2], anno['bbox'][3],\n",
    "                linewidth=1,edgecolor='r',facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "    \n",
    "    ax.imshow(im)\n",
    "    ax.axis('off')\n",
    "    ax.set_title(nm)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 IoU of the detected pattern w.r.t. the ground truth\n",
    "\n",
    "Add your implementation and discussion\n",
    "\n",
    "Hint: `skimage.measure.regionprops` implements a large variety of descriptors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour cette partie, il nous faut connaitre les coordonnées des rectangles représentant chaque mite. Comme il nous manque un critère suffisant pour calculer les dimensions et coordonnées de ces rectangles, nous avons opté pour une autre méthode. Nous utilisons uniquement le point central de chaque mite, et par rapport à celui-ci, nous estimons l'intersection over union. La méthode est simple. Nous imaginons que notre mite est représentée par un rectangle contenant les même dimensions que celui du ground truth, et part rapport à ça, nous pouvons appliquer un calcul de l'intersection et de l'union basé uniquement sur le désaxage du centre de notre mite, et du centre de la mite du ground truth. Ce calcul nous donne : Ainter = (width - deltaX)(height - deltaY), Aunion = 2*width*height - Ainter, où deltaX et deltaY représente le désaxage en x et y du centre de la mite avec le ground truth, et height et width représente les dimensions du rectangle représentant la mite du ground truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeTP(centers, xmin, ymin, xmax, ymax, threshold):\n",
    "    # true positive\n",
    "    nombre = 0\n",
    "    xmin = list(xmin)\n",
    "    ymin = list(ymin)\n",
    "    xmax = list(xmax)\n",
    "    ymax = list(ymax)\n",
    "    for i in range(len(centers)):\n",
    "         for j in range(len(xmin)):\n",
    "                if(centers[i,1] < xmax[j]) and (centers[i,1] > xmin[j]) and (centers[i,0] < ymax[j]) and (centers[i,0] > ymin[j]):\n",
    "                    #computation of intersection over union\n",
    "                    width = xmax[j] - xmin[j]\n",
    "                    height = ymax[j] - ymin[j]\n",
    "                    meanX = (xmax[j] + xmin[j])/2\n",
    "                    meanY = (ymax[j] + ymin[j])/2\n",
    "                    deltaX = abs(centers[i,1] - meanX)\n",
    "                    deltaY = abs(centers[i,0] - meanY)\n",
    "                    Ainter = (width - deltaX)*(height - deltaY)\n",
    "                    Aunion = 2*width*height - Ainter\n",
    "                    interOverUnion = Ainter/Aunion\n",
    "                    if(interOverUnion > threshold):\n",
    "                        nombre = nombre + 1\n",
    "                        del xmin[j]\n",
    "                        del ymin[j]\n",
    "                        del xmax[j]\n",
    "                        del ymax[j]\n",
    "                        break     \n",
    "    return nombre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeFP(centers, xmin, ymin, xmax, ymax, threshold):\n",
    "    # false positive\n",
    "    nombre = 0\n",
    "    xmin = list(xmin)\n",
    "    ymin = list(ymin)\n",
    "    xmax = list(xmax)\n",
    "    ymax = list(ymax)\n",
    "    for i in range(len(centers)):\n",
    "        if(len(xmin) == 0):\n",
    "            nombre = nombre + 1\n",
    "        else:\n",
    "            for j in range(len(xmin)):\n",
    "                if(centers[i,1] < xmax[j]) and (centers[i,1] > xmin[j]) and (centers[i,0] < ymax[j]) and (centers[i,0] > ymin[j]):\n",
    "                     #computation of intersection over union\n",
    "                    width = xmax[j] - xmin[j]\n",
    "                    height = ymax[j] - ymin[j]\n",
    "                    meanX = (xmax[j] + xmin[j])/2\n",
    "                    meanY = (ymax[j] + ymin[j])/2\n",
    "                    deltaX = abs(centers[i,1] - meanX)\n",
    "                    deltaY = abs(centers[i,0] - meanY)\n",
    "                    Ainter = (width - deltaX)*(height - deltaY)\n",
    "                    Aunion = 2*width*height - Ainter\n",
    "                    interOverUnion = Ainter/Aunion\n",
    "                    if(interOverUnion > threshold):\n",
    "                        del xmin[j]\n",
    "                        del ymin[j]\n",
    "                        del xmax[j]\n",
    "                        del ymax[j]\n",
    "                        break   \n",
    "                if(j == (len(xmin) - 1)):\n",
    "                    nombre = nombre + 1\n",
    "            \n",
    "    return nombre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeFN(centers, xmin, ymin, xmax, ymax, threshold):\n",
    "    #false negative\n",
    "    nombre = 0\n",
    "    xmin = list(xmin)\n",
    "    ymin = list(ymin)\n",
    "    xmax = list(xmax)\n",
    "    ymax = list(ymax)\n",
    "    centers_y = list(centers[:,0])\n",
    "    centers_x = list(centers[:,1])\n",
    "    for j in range(len(xmin)):\n",
    "        if(len(centers_x) == 0):\n",
    "            nombre = nombre + 1\n",
    "        else :\n",
    "            for i in range(len(centers_x)):\n",
    "                if(centers_x[i] < xmax[j]) and (centers_x[i] > xmin[j]) and (centers_y[i] < ymax[j]) and (centers_y[i] > ymin[j]):\n",
    "                     #computation of intersection over union\n",
    "                    width = xmax[j] - xmin[j]\n",
    "                    height = ymax[j] - ymin[j]\n",
    "                    meanX = (xmax[j] + xmin[j])/2\n",
    "                    meanY = (ymax[j] + ymin[j])/2\n",
    "                    deltaX = abs(centers_x[i] - meanX)\n",
    "                    deltaY = abs(centers_y[i] - meanY)\n",
    "                    Ainter = (width - deltaX)*(height - deltaY)\n",
    "                    Aunion = 2*width*height - Ainter\n",
    "                    interOverUnion = Ainter/Aunion\n",
    "                    if(interOverUnion > threshold):\n",
    "                        del centers_x[i]\n",
    "                        del centers_y[i]\n",
    "                        break    \n",
    "                if(i == len(centers_x) - 1):\n",
    "                    nombre = nombre + 1\n",
    "    return nombre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'axes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-5b60e4ebb3f6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mthreshold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mannotations\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mic\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mim_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mannotations_xmls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[1;31m# Iterate over annotations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0manno\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mannotations\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'axes' is not defined"
     ]
    }
   ],
   "source": [
    "ground_truth_xmin = []\n",
    "ground_truth_ymin = []\n",
    "ground_truth_xmax = []\n",
    "ground_truth_ymax = []\n",
    "\n",
    "#threshold for intersection over union\n",
    "threshold = 0.2\n",
    "\n",
    "for ax, im, nm, annotations in zip(axes.ravel(), ic, im_names, annotations_xmls):\n",
    "    # Iterate over annotations\n",
    "    for anno in annotations:\n",
    "        ground_truth_xmin.append(anno['bbox'][0])\n",
    "        ground_truth_ymin.append(anno['bbox'][1])\n",
    "        ground_truth_xmax.append(anno['bbox'][2] + anno['bbox'][0])\n",
    "        ground_truth_ymax.append(anno['bbox'][3] + anno['bbox'][1])\n",
    "\n",
    "center = computeCenterPoints(varroa)\n",
    "    \n",
    "tp = computeTP(center, ground_truth_xmin, ground_truth_ymin, ground_truth_xmax, ground_truth_ymax, threshold)\n",
    "print('true positive = {}'.format(tp))\n",
    "fp = computeFP(center, ground_truth_xmin, ground_truth_ymin, ground_truth_xmax, ground_truth_ymax, threshold)\n",
    "print('false positive = {}'.format(fp))\n",
    "fn = computeFN(center, ground_truth_xmin, ground_truth_ymin, ground_truth_xmax, ground_truth_ymax, threshold)\n",
    "print('false negative = {}'.format(fn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Precision, Recall and F1-score at two different IoU thresholds\n",
    "\n",
    "Add your implementation and discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme nous venons de calculer tp, fp, et fn juste avant, cette étape est triviale. Concernant les résultats, nous sommes plutôt satisfait car dans la plupart des cas, nous estimons bien le nombre de mites. Néanmoins, nous modifions des paramètre entre chaque image. Il serait bien de pouvoir automatiser cette tâche. Pour ce faire, il aurait été intéressant de disposer de détails supplémentaires concernant les images, comme l'agrandissement de l'image, et la taille et forme réelle d'une mite. Ainsi nous aurions pu tester d'autres techniques, comme le \"matching\" de l'image avec un masque qui contient une mite idéale. L'agrandissement de la photo nous permettrait là d'adapter la taille du masque selon la photo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(tp + fp) == 0:\n",
    "    precision = 0\n",
    "else:\n",
    "    precision = tp/(tp+fp)\n",
    "\n",
    "if(tp + fn) == 0:\n",
    "    recall = 0\n",
    "else:\n",
    "    recall = tp/(tp+fn)\n",
    "\n",
    "if(precision + recall) == 0:\n",
    "    F1_score = 0\n",
    "else:\n",
    "    F1_score = (2*precision*recall/(precision+recall))\n",
    "print(F1_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

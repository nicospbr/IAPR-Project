{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import cv2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from mpl_toolkits.mplot3d.axes3d import Axes3D\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def parse_file(filename):\n",
    "    \"\"\" Parse a PASCAL VOC xml file \"\"\"\n",
    "    tree = ET.parse(filename)\n",
    "    objects = []\n",
    "    for obj in tree.findall('object'):\n",
    "        obj_struct = {}\n",
    "        obj_struct['name'] = obj.find('name').text\n",
    "        bbox = obj.find('bndbox')\n",
    "        obj_struct['bbox'] = [int(float(bbox.find('xmin').text)),\n",
    "                              int(float(bbox.find('ymin').text)),\n",
    "                              int(float(bbox.find('xmax').text))-int(float(bbox.find('xmin').text)),\n",
    "                              int(float(bbox.find('ymax').text))-int(float(bbox.find('ymin').text))]\n",
    "        objects.append(obj_struct)\n",
    "\n",
    "    return objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path='Data/'\n",
    "img_path='images/'\n",
    "annotations_path='annotations/'\n",
    "train_path='train/'\n",
    "test_path='test/'\n",
    "val_path='validation/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dataframe to store the cooridnates of bounding box for each image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_to_df(path_images, path_annotations):\n",
    "    \"\"\"\n",
    "    Load data annotations coordinates into a dataframe\n",
    "    \"\"\"\n",
    "    \n",
    "    df= pd.DataFrame()\n",
    "    im_names=os.listdir(path_images)\n",
    "    im_names=[name[:-4] for name in im_names] #get rid of the .jpg\n",
    "    \n",
    "    i=0\n",
    "    for name in im_names:\n",
    "        anno=parse_file(os.path.join(path_annotations, name) + '.xml')\n",
    "        for dic in anno:\n",
    "            df.loc[i,'filename']=name\n",
    "            df.loc[i,'xmin']=dic['bbox'][0]\n",
    "            df.loc[i,'ymin']=dic['bbox'][1]\n",
    "            df.loc[i,'xmax']=dic['bbox'][2] + dic['bbox'][0]\n",
    "            df.loc[i,'ymax']=dic['bbox'][3] + dic['bbox'][1]\n",
    "            i+=1\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_anno=data_path+annotations_path +train_path\n",
    "df_train=data_to_df(data_path+img_path+train_path, tr_anno)\n",
    "\n",
    "with open('df_train.pickle', 'wb') as df:\n",
    "    pickle.dump(df_train, df, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "te_anno=data_path+annotations_path +test_path\n",
    "df_test=data_to_df(data_path+img_path+test_path, te_anno)\n",
    "\n",
    "with open('df_test.pickle', 'wb') as df:\n",
    "    pickle.dump(df_test, df, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_anno=data_path+annotations_path +val_path\n",
    "df_val=data_to_df(data_path+img_path+val_path, val_anno)\n",
    "\n",
    "with open('df_val.pickle', 'wb') as df:\n",
    "    pickle.dump(df_val, df, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb of train images : 532\n",
      "Nb of test images : 33\n",
      "Nb of validation images : 103\n"
     ]
    }
   ],
   "source": [
    "print('Nb of train images :',df_train.filename.nunique())\n",
    "print('Nb of test images :',df_test.filename.nunique())\n",
    "print('Nb of validation images :',df_val.filename.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For R-CNN potential model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def formating(data_dir,row):\n",
    "    \"\"\"\n",
    "    Puts the annotations and the filename in the correct format\n",
    "    for RNN training:\n",
    "        filepath,x1,y1,x2,y2,class_name\n",
    "    \"\"\"\n",
    "    anno=data_dir+row[0]+'.jpg,'+str(int(row[1]))+','+\\\n",
    "        str(int(row[2]))+','+str(int(row[3]))+','+str(int(row[4]))+',Varroa'\n",
    "    return anno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir=data_path+img_path+train_path\n",
    "train_anno=pd.DataFrame()\n",
    "train_anno['format']=df_train.apply(lambda row: formating('../'+train_dir, row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>format</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../Data/images/train/59023fbd579e52581ddede9f_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../Data/images/train/59023fbd579e52581ddede9f_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../Data/images/train/59023fbd579e52581ddede9f_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../Data/images/train/59023fbd579e52581ddede9f_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../Data/images/train/59023fbd579e52581ddede9f_...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              format\n",
       "0  ../Data/images/train/59023fbd579e52581ddede9f_...\n",
       "1  ../Data/images/train/59023fbd579e52581ddede9f_...\n",
       "2  ../Data/images/train/59023fbd579e52581ddede9f_...\n",
       "3  ../Data/images/train/59023fbd579e52581ddede9f_...\n",
       "4  ../Data/images/train/59023fbd579e52581ddede9f_..."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_anno.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_anno.to_csv('annotate.txt', header=None, index=None, sep=' ')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (TF)",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
